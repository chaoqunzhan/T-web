# 大文件上传

面试官再问你大文件上传，你就把这些知识点甩给他：

### 1. 分片上传 (Chunked Upload)

*   原理： 前端利用 File.slice() API 将大文件切割成多个固定大小的小块（例如每片 5MB），然后逐个上传这些小分片。后端接收所有分片后，根据索引将它们重新拼接成完整的文件。
*   解决的问题：
    *   超时问题： 避免单次 HTTP 请求时间过长导致的超时中断。
    *   内存溢出： 避免一次性读取大文件到内存中导致浏览器或服务器崩溃。
    *   带宽占用： 减少单个请求对带宽的独占，提升网络利用率。

### 2. 断点续传 (Resume from Breakpoint) 
这是提升用户体验的关键。试想上传了 90% 失败了，如果能接着传而不是重头开始，用户会非常满意。

*   原理： 上传前，前端请求后端查询该文件（通常通过唯一标识 Hash）已上传的分片列表。前端拿到列表后，跳过已上传的分片，只上传缺失的部分。
*   关键技术点：
    *   文件唯一标识： 必须有一个 ID 来区分不同的文件上传任务，通常使用文件的 Hash 值。
    *   状态记录： 后端需要存储每个文件上传任务的进度（例如存入 Redis 或数据库），记录哪些分片已成功接收。

### 3. 秒传 (Instant Upload) 
文件还没传，就显示成功了？这就是秒传。

*   原理： 在上传开始前，先计算整个文件的哈希值（如 MD5），发送给后端校验。如果后端发现该哈希值的文件已经存在（可能是别人已经上传过了），就直接返回上传成功，无需再传输文件流。
*   实现难点： 前端计算大文件哈希可能会阻塞页面，通常需要使用 SparkMD5 等库配合 FileReader 分块异步读取计算，避免卡顿。

### 4. 进阶增强
除了上述“三件套”，更完善的方案还包含以下知识点：

*   并发控制： 分片上传时，如果一次性发送所有请求可能会压垮服务器。通常使用 Promise Pool 限制同时上传的分片数量（例如同时只传 3-5 个），传完一个再补一个。
*   上传进度： 由于是多请求并发，计算总进度需要汇总所有分片的上传情况（已上传字节数 / 总字节数），而不仅仅是监听单个请求的进度。
*   错误重试与指数退避： 网络不稳定时，分片上传可能会失败。需要对失败的分片进行自动重试，且重试间隔时间应逐渐增加（指数退避），避免频繁无效请求。
*   OSS 直传： 为了减轻应用服务器的压力，可以让前端直接与对象存储服务（如阿里云 OSS、AWS S3）交互上传文件，文件流不经过业务服务器，实现带宽和存储的解耦。

### 5. 关键技术栈

|技术点|关键 API / 概念|作用|
|--|--|--|
|文件切片|File.slice(start, end)|浏览器原生 API，用于切割文件生成 Blob 对象。|
|计算哈希|FileReader + SparkMD5|分块读取文件内容并计算唯一指纹，用于秒传和断点续传。|
|HTTP 协议|Range 请求头|虽然分片上传常用自定义协议，但 Range 是 HTTP 标准的范围请求机制。|
|传输安全|HTTPS|大文件传输时间长，必须使用加密协议防止数据被劫持。|
|数据校验|MD5/SHA 校验|确保文件或分片在传输过程中没有损坏。|

### 总结
一个成熟的大文件上传方案通常是：先计算文件 Hash -> 校验是否秒传 -> 获取已上传分片列表（断点续传） -> 多线程并发上传剩余分片 -> 所有分片上传成功后通知服务端合并。

